{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Dec 25 00:44:54 2019\n",
    "\n",
    "@author: ziyingfeng\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import heapq\n",
    "from surprise import Dataset, Reader\n",
    "from surprise import SVD, NMF\n",
    "from surprise.similarities import cosine, msd, pearson\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Using Surprise package instead of Sklearn\n",
    "    Because Surprise has its own SGD, therefore it can deal with sparse matrix\n",
    "    For Sklearn, we need to fill the NAN with numbers it is not practical here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  item_id  rating  timestamp\n",
      "0      196      242       3  881250949\n",
      "1      186      302       3  891717742\n",
      "2       22      377       1  878887116\n",
      "3      244       51       2  880606923\n",
      "4      166      346       1  886397596\n"
     ]
    }
   ],
   "source": [
    "columns = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "data = pd.read_csv('ml-100k/u.data', sep = '\\t', names = columns)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(943, 1682)\n",
      "user_id  1    2    3    4    5    6    7    8    9    10   ...  934  935  936  \\\n",
      "item_id                                                    ...                  \n",
      "1        5.0  4.0  NaN  NaN  4.0  4.0  NaN  NaN  NaN  4.0  ...  2.0  3.0  4.0   \n",
      "2        3.0  NaN  NaN  NaN  3.0  NaN  NaN  NaN  NaN  NaN  ...  4.0  NaN  NaN   \n",
      "3        4.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  4.0   \n",
      "4        3.0  NaN  NaN  NaN  NaN  NaN  5.0  NaN  NaN  4.0  ...  5.0  NaN  NaN   \n",
      "5        3.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
      "...      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "1678     NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
      "1679     NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
      "1680     NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
      "1681     NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
      "1682     NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
      "\n",
      "user_id  937  938  939  940  941  942  943  \n",
      "item_id                                     \n",
      "1        NaN  4.0  NaN  NaN  5.0  NaN  NaN  \n",
      "2        NaN  NaN  NaN  NaN  NaN  NaN  5.0  \n",
      "3        NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "4        NaN  NaN  NaN  2.0  NaN  NaN  NaN  \n",
      "5        NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "...      ...  ...  ...  ...  ...  ...  ...  \n",
      "1678     NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "1679     NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "1680     NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "1681     NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "1682     NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "\n",
      "[1682 rows x 943 columns]\n"
     ]
    }
   ],
   "source": [
    "# In Surprise package we don't need this part\n",
    "# Here just generate a utility matrix for reference\n",
    "utilityMatrix = pd.pivot_table(data, values = 'rating', \n",
    "                               index = 'user_id', \n",
    "                               columns = 'item_id', \n",
    "                               aggfunc = np.max)\n",
    "print(utilityMatrix.shape)\n",
    "movieUtilityMatrix = utilityMatrix.T\n",
    "print(movieUtilityMatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Surprise has its own data input handle methods\n",
    "    We need to use reader to read the dataframe and convert to trainset\n",
    "    Since we are care doing item_based, care about similarity between items, we change the column order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale = (1, 5))\n",
    "item_based_data = Dataset.load_from_df(data[['item_id', 'user_id', 'rating']], reader)\n",
    "full_trainset = item_based_data.build_full_trainset()\n",
    "trainSet, testSet = train_test_split(item_based_data, test_size = 0.2, random_state = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test for the Missing Ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Model choosing NMF or SVD for matrix factorization\n",
    "    NMF (Non-negative Matrix Factorization)\n",
    "    SVD (Singular Vector Decomposition)\n",
    "    random_state is seed so that the result could be repeated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMF model RMSE is 0.962\n",
      "SVD model RMSE is 0.928\n"
     ]
    }
   ],
   "source": [
    "model_NMF = NMF(n_factors = 15, random_state = 10)\n",
    "model_SVD = SVD(n_factors = 15, random_state = 10)\n",
    "\n",
    "model_NMF.fit(trainSet)\n",
    "model_SVD.fit(trainSet)\n",
    "\n",
    "# Use both models to predict the NAN ratings\n",
    "# Check the RMSE of the predictions, RMSE is calculated based on the non-NAN value in the testSet\n",
    "predictions_NMF = model_NMF.test(testSet)\n",
    "predictions_SVD = model_SVD.test(testSet)\n",
    "print(\"NMF model RMSE is {:.3f}\".format(accuracy.rmse(predictions_NMF, verbose = False)))\n",
    "print(\"SVD model RMSE is {:.3f}\".format(accuracy.rmse(predictions_SVD, verbose = False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Use the model in the whole dataset, and use similarity to recommend similar item (movie)\n",
    "    The default similarity computation method MSD (Mean Square Difference), here we choose Pearson Difference\n",
    "    Since we have change the column order in the \"Convert Data\" part, so for 'user_based' we set True here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x10faf3780>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_trainset = item_based_data.build_full_trainset()\n",
    "model_NMF_fullTrainSet = NMF(n_factors = 15, random_state = 10)\n",
    "model_NMF_fullTrainSet.sim_options = {'name':'pearson', 'user_based':True}\n",
    "model_SVD_fullTrainSet = SVD(n_factors = 15, random_state = 10)\n",
    "model_SVD_fullTrainSet.sim_options = {'name':'pearson', 'user_based':True}\n",
    "model_NMF_fullTrainSet.fit(full_trainset)\n",
    "model_SVD_fullTrainSet.fit(full_trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMF similarity matrix shape:  (1682, 1682)\n",
      "SVD similarity matrix shape:  (1682, 1682)\n",
      "\n",
      "Print the first 7 rows and 7 columns of the NMF similarity matrix:\n",
      "[[ 1.          0.42799905  0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.42799905  1.          0.13363062 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.13363062  1.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.07430376  0.2994642   0.78107061 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.56612358  0.24559122  0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [-0.10081339  0.22424013  0.         ...  0.          0.\n",
      "   0.        ]]\n",
      "\n",
      "Print the first 7 rows and 7 columns of the SVD similarity matrix:\n",
      "[[ 1.          0.42799905  0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.42799905  1.          0.13363062 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.13363062  1.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.07430376  0.2994642   0.78107061 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.56612358  0.24559122  0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [-0.10081339  0.22424013  0.         ...  0.          0.\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "simMatrix_NMF = model_NMF_fullTrainSet.compute_similarities() \n",
    "simMatrix_SVD = model_SVD_fullTrainSet.compute_similarities()\n",
    "print('NMF similarity matrix shape: ', simMatrix_NMF.shape)\n",
    "print('SVD similarity matrix shape: ', simMatrix_SVD.shape)\n",
    "\n",
    "print('\\nPrint the first 7 rows and 7 columns of the NMF similarity matrix:')\n",
    "print(simMatrix_NMF[0:6][0:6])\n",
    "print('\\nPrint the first 7 rows and 7 columns of the SVD similarity matrix:')\n",
    "print(simMatrix_SVD[0:6][0:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Similar Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print part of the item_id and the corresponding movie_title:\n",
      "   item_id                                        movie_title\n",
      "0        1                                   Toy Story (1995)\n",
      "1        2                                   GoldenEye (1995)\n",
      "2        3                                  Four Rooms (1995)\n",
      "3        4                                  Get Shorty (1995)\n",
      "4        5                                     Copycat (1995)\n",
      "5        6  Shanghai Triad (Yao a yao yao dao waipo qiao) ...\n",
      "6        7                              Twelve Monkeys (1995)\n",
      "7        8                                        Babe (1995)\n",
      "8        9                            Dead Man Walking (1995)\n",
      "\n",
      " Select a movie that I like, and find its item_id\n",
      "    item_id       movie_title\n",
      "49       50  Star Wars (1977)\n"
     ]
    }
   ],
   "source": [
    "# Import the user_id and movie_title mapping data\n",
    "items = pd.read_csv('ml-100k/u.item', sep = '|', header = None, encoding = 'latin-1')\n",
    "items = items.iloc[:, 0:2]\n",
    "items.columns = ['item_id', 'movie_title']\n",
    "print('Print part of the item_id and the corresponding movie_title:')\n",
    "print(items.iloc[0:9, :])\n",
    "\n",
    "# Select a movie and later we will recommend movies similar to this\n",
    "print('\\n Select a movie that I like, and find its item_id')\n",
    "print(items[items['movie_title'].str.contains('Star Wars')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Similarities based on the selected movie \n",
      " [ 0.05365553  0.24856031 -0.875      ...  0.          0.\n",
      "  0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Similarity of this selected movie and the others\n",
    "sim_selected = simMatrix_NMF[49]\n",
    "print('\\n Similarities based on the selected movie \\n', sim_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1.0, 343), (1.0, 398), (1.0, 448), (1.0, 626), (1.0, 1085), (1.0, 1153), (1.0, 1160), (1.0, 1135), (1.0, 788), (1.0, 1308)]\n"
     ]
    }
   ],
   "source": [
    "# Find the indices of the k most similar items with heap\n",
    "k = 10\n",
    "k_sim_idx_heap = []\n",
    "for i in range(len(sim_selected)):\n",
    "    if i == 49:\n",
    "        continue\n",
    "    if len(k_sim_idx_heap) < k:\n",
    "        heapq.heappush(k_sim_idx_heap, (sim_selected[i], i))\n",
    "    else:\n",
    "        if sim_selected[i] > k_sim_idx_heap[0][0]:\n",
    "            heapq.heappop(k_sim_idx_heap)\n",
    "            heapq.heappush(k_sim_idx_heap, (sim_selected[i], i))\n",
    "print(k_sim_idx_heap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The recommemed movies are:\n",
      "Very Natural Thing, A (1974)\n",
      "Swimming with Sharks (1995)\n",
      "Ghosts of Mississippi (1996)\n",
      "Palookaville (1996)\n",
      "Alphaville (1965)\n",
      "It's My Party (1995)\n",
      "Robin Hood: Prince of Thieves (1991)\n",
      "Star Trek: The Motion Picture (1979)\n",
      "Three Musketeers, The (1993)\n",
      "Apostle, The (1997)\n"
     ]
    }
   ],
   "source": [
    "# print out the corresponding movie_title\n",
    "# since it is min heap, when printing we print from the last item to the first item\n",
    "print('\\n The recommemed movies are:')\n",
    "for i in range(len(k_sim_idx_heap)-1, -1, -1):\n",
    "    idx = k_sim_idx_heap[i][1]\n",
    "    print(items.iloc[idx, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
